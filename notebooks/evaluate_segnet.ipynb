{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe28bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5972ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from data import SegDataset, CLASS_MAP_VOID, crop_augment_preprocess_batch, NUM_CLASSES_VOID, get_image_UIDs\n",
    "from models.seg_models import evaluate\n",
    "from path import SPLITS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e0d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import segmentation as segmodels\n",
    "from torchvision.transforms._presets import SemanticSegmentation\n",
    "from functools import partial\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassJaccardIndex\n",
    "import torchvision.transforms.v2 as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be2fa6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c29f46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SegDataset(get_image_UIDs(SPLITS_PATH, split=\"train\", shuffle=False), resize_size=CONFIG['segnet']['image_size'], class_map=CLASS_MAP_VOID)\n",
    "val_ds = SegDataset(get_image_UIDs(SPLITS_PATH, split=\"train\", shuffle=False), resize_size=CONFIG['segnet']['image_size'], class_map=CLASS_MAP_VOID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b29ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segmodels.lraspp_mobilenet_v3_large(weights=None, weights_backbone=None).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(TORCH_WEIGHTS_CHECKPOINTS / (\"lraspp_mobilenet_v3_large-full-pt\" + \".pth\")))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76c834d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_crop_module = T.CenterCrop(CONFIG['segnet']['image_size'])\n",
    "random_crop_module = T.RandomCrop(CONFIG['segnet']['image_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd530169",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = partial(SemanticSegmentation, resize_size=CONFIG['segnet']['image_size'])()\n",
    "train_collate_fn = partial(crop_augment_preprocess_batch, crop_fn=T.CenterCrop(CONFIG['segnet']['image_size']), augment_fn=None, preprocess_fn=preprocess)\n",
    "val_collate_fn = partial(crop_augment_preprocess_batch, crop_fn=lambda x, y: (x, y), augment_fn=None, preprocess_fn=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82232252",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6de6fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=CONFIG[\"segnet\"]['train'][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    generator=TORCH_GEN.clone_state(),\n",
    "    collate_fn=train_collate_fn,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    generator=TORCH_GEN.clone_state(),\n",
    "    collate_fn=val_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5f0a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    \"acc\": MulticlassAccuracy(num_classes=NUM_CLASSES_VOID, top_k=1, average=\"micro\", multidim_average=\"global\", ignore_index=21).to(CONFIG[\"device\"]),\n",
    "    \"IoU_per_class\": MulticlassJaccardIndex(NUM_CLASSES_VOID, average=None, ignore_index=21, zero_division=torch.nan).to(CONFIG[\"device\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3515ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22833188439978927,\n",
       " {'IoU_per_class': tensor([0.9096, 0.8566, 0.4046, 0.8583, 0.6919, 0.5531, 0.8731, 0.5510, 0.8985,\n",
       "          0.2652, 0.8288, 0.6749, 0.8436, 0.8541, 0.7938, 0.8442, 0.4622, 0.8573,\n",
       "          0.4624, 0.8740, 0.6180,    nan], device='cuda:0'),\n",
       "  'acc': tensor(0.9222, device='cuda:0')})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_metrics_score = evaluate(model, train_dl, criterion, metrics_dict)\n",
    "train_loss, train_metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80e86cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7131, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_metrics_score[\"IoU_per_class\"].nanmean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33b29672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2163727689334675,\n",
       " {'IoU_per_class': tensor([0.9198, 0.8524, 0.3711, 0.8392, 0.6574, 0.5793, 0.8627, 0.5535, 0.8884,\n",
       "          0.3370, 0.8183, 0.5975, 0.8327, 0.8495, 0.7918, 0.8278, 0.4517, 0.8418,\n",
       "          0.4489, 0.8613, 0.5966,    nan], device='cuda:0'),\n",
       "  'acc': tensor(0.9283, device='cuda:0')})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_metrics_score = evaluate(model, val_dl, criterion, metrics_dict)\n",
    "val_loss, val_metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6187fd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7037, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(val_metrics_score[\"IoU_per_class\"].nanmean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
