{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5972ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from data import SegDataset, image_train_UIDs, image_val_UIDs, CLASS_MAP_VOID, crop_augment_preprocess_batch, NUM_CLASSES_VOID\n",
    "from models.vl_models import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import segmentation as segmodels\n",
    "from torchvision.transforms._presets import SemanticSegmentation\n",
    "from functools import partial\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassJaccardIndex\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be2fa6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29f46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SegDataset(image_train_UIDs, resize_size=CONFIG['seg']['image_size'], class_map=CLASS_MAP_VOID)\n",
    "val_ds = SegDataset(image_val_UIDs, resize_size=CONFIG['seg']['image_size'], class_map=CLASS_MAP_VOID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segmodels.lraspp_mobilenet_v3_large(weights=None, weights_backbone=None).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(TORCH_WEIGHTS_CHECKPOINTS / (\"lraspp_mobilenet_v3_large-full-pt\" + \".pth\")))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c834d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_crop_module = T.CenterCrop(CONFIG['seg']['image_size'])\n",
    "random_crop_module = T.RandomCrop(CONFIG['seg']['image_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd530169",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = partial(SemanticSegmentation, resize_size=CONFIG['seg']['image_size'])()\n",
    "train_collate_fn = partial(crop_augment_preprocess_batch, crop_module=T.CenterCrop(CONFIG['seg']['image_size']), augment_fn=None, preprocess_fn=preprocess)\n",
    "val_collate_fn = partial(crop_augment_preprocess_batch, crop_module=lambda x, y: (x, y), augment_fn=None, preprocess_fn=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82232252",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=CONFIG[\"seg\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    generator=TORCH_GEN.clone_state(),\n",
    "    collate_fn=train_collate_fn,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    generator=TORCH_GEN.clone_state(),\n",
    "    collate_fn=val_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f0a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    \"acc\": MulticlassAccuracy(num_classes=NUM_CLASSES_VOID, top_k=1, average=\"micro\", multidim_average=\"global\", ignore_index=21).to(CONFIG[\"device\"]),\n",
    "    \"IoU_per_class\": MulticlassJaccardIndex(NUM_CLASSES_VOID, average=None, ignore_index=21, zero_division=torch.nan).to(CONFIG[\"device\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3515ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22815202925700306,\n",
       " {'IoU_per_class': tensor([0.9096, 0.8566, 0.4038, 0.8585, 0.6917, 0.5530, 0.8724, 0.5522, 0.8974,\n",
       "          0.2665, 0.8278, 0.6740, 0.8436, 0.8540, 0.7945, 0.8437, 0.4622, 0.8569,\n",
       "          0.4651, 0.8744, 0.6183,    nan], device='cuda:0'),\n",
       "  'acc': tensor(0.9222, device='cuda:0')})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_metrics_score = evaluate(model, train_dl, criterion, metrics_dict)\n",
    "train_loss, train_metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e86cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7131, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(train_metrics_score[\"IoU_per_class\"].nanmean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b29672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20719398433272518,\n",
       " {'IoU_per_class': tensor([0.9220, 0.8434, 0.3509, 0.8503, 0.6659, 0.5618, 0.8918, 0.6914, 0.8643,\n",
       "          0.3536, 0.8243, 0.4685, 0.7804, 0.8229, 0.7969, 0.8273, 0.5317, 0.7762,\n",
       "          0.5054, 0.8581, 0.6442,    nan], device='cuda:0'),\n",
       "  'acc': tensor(0.9301, device='cuda:0')})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_metrics_score = evaluate(model, val_dl, criterion, metrics_dict)\n",
    "val_loss, val_metrics_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6187fd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7063, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(val_metrics_score[\"IoU_per_class\"].nanmean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
