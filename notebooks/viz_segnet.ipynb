{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7a68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df37e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from color_map import apply_colormap\n",
    "from path import get_mask_prs_path, SCS_PATH, GTS_PATH\n",
    "from data import VOC2012SegDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e32d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import segmentation as segmodels\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.transforms._presets import SemanticSegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ca313",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c29d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/olivieri/exp/data/torch_weights\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.hub.get_dir())\n",
    "print(CONFIG[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63588ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/olivieri/exp/data/prompts_data/by_model/LRASPP_MobileNet_V3/_mask_prs_')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BY_MODEL = \"LRASPP_MobileNet_V3\"\n",
    "SPLIT_BY = \"non-splitted\"\n",
    "\n",
    "mask_prs_path = get_mask_prs_path(BY_MODEL)\n",
    "mask_prs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15141109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = segmodels.lraspp_mobilenet_v3_large(weights=None, weights_backbone=None).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(Path(CONFIG['seg']['pretrained_weights_root_path']) / (\"lraspp_mobilenet_v3_large-full-pt\" + \".pth\")))\n",
    "model.eval()\n",
    "\n",
    "preprocess = partial(SemanticSegmentation, resize_size=CONFIG['seg']['image_size'])() # same as default transforms, but with custom resizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f44ee",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b6d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dataset = VOC2012SegDataset(\n",
    "    root_path=Path(\"/home/olivieri/exp/data/VOCdevkit\"),\n",
    "    split='train',\n",
    "    resize_size=520,\n",
    "    center_crop=True,\n",
    "    with_unlabelled=False,\n",
    "    mask_prs_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51cce283",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(0, 8))\n",
    "\n",
    "scs_list, gts_list = seg_dataset[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32caea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 520, 520]), torch.Size([8, 1, 520, 520]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scs = torch.stack(scs_list, dim=0)\n",
    "gts = torch.stack(gts_list, dim=0)\n",
    "scs.shape, gts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fd95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 520, 520])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = preprocess(scs)\n",
    "logits = model(x)[\"out\"]\n",
    "prs = logits.argmax(dim=1, keepdim=True).float()\n",
    "assert scs.shape[2:] == gts.shape[2:] == prs.shape[2:]\n",
    "prs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64a2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_UIDs = seg_dataset.get_image_UIDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(idxs):\n",
    "    pr_col = apply_colormap([prs[i]], seg_dataset.get_color_map_dict(with_unlabelled=False))[0]\n",
    "    # gt_col = apply_colormap([gts[i]], seg_dataset.get_color_map_dict(with_void=False))[0]\n",
    "    pr_col_img = to_pil_image(pr_col)\n",
    "    # gt_col_img = to_pil_image(gt_col)\n",
    "    # sc_img = to_pil_image(scs[i])\n",
    "\n",
    "    # pr_ovr = Image.blend(sc_img, pr_col_img, 0.8)\n",
    "    # gt_ovr = Image.blend(sc_img, gt_col_img, 0.8)\n",
    "    \n",
    "    # concat_imgs = Image.new('RGB', (pr_ovr.width + gt_ovr.width, pr_ovr.height))\n",
    "    # concat_imgs.paste(pr_ovr, (0, 0))\n",
    "    # concat_imgs.paste(gt_ovr, (pr_ovr.width, 0))\n",
    "\n",
    "    # torchvision.utils.save_image(prs[i]/255., f'/home/olivieri/exp/data/prompts_data/by_model/LRASPP_MobileNet_V3/_mask_prs_/mask_pr_{idx}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a25d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
