{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60375c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d74de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0b1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_accuracies(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract batch accuracies for each epoch and step.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary where the outer keys are epoch numbers and the\n",
    "        inner keys are step numbers, with batch accuracy as the value.\n",
    "        Example: {1: {5: 0.9739, 10: 0.9783}, 2: {...}}\n",
    "    \"\"\"\n",
    "    # Regex to capture epoch, step, and batch_acc\n",
    "    # It looks for lines like: \"[epoch: 1/20, step: 5/46 ... batch_acc: 0.9739 ...\"\n",
    "    log_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+, step: (\\d+)/\\d+ .*?batch_acc: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    accuracies = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                match = log_pattern.search(line)\n",
    "                if match:\n",
    "                    # Extract captured groups\n",
    "                    epoch = int(match.group(1))\n",
    "                    step = int(match.group(2))\n",
    "                    batch_acc = float(match.group(3))\n",
    "\n",
    "                    # Populate the nested dictionary\n",
    "                    if epoch not in accuracies:\n",
    "                        accuracies[epoch] = {}\n",
    "                    \n",
    "                    accuracies[epoch][step] = batch_acc\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_aux_losses(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract batch_aux_loss for each epoch and step.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary of the form: {epoch: {step: aux_loss}}\n",
    "    \"\"\"\n",
    "    # Regex is adjusted to capture 'batch_aux_loss' instead of 'batch_acc'\n",
    "    log_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+, step: (\\d+)/\\d+ .*?batch_aux_loss: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    aux_losses = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                match = log_pattern.search(line)\n",
    "                if match:\n",
    "                    # Extract captured groups\n",
    "                    epoch = int(match.group(1))\n",
    "                    step = int(match.group(2))\n",
    "                    batch_aux_loss = float(match.group(3))\n",
    "\n",
    "                    # Populate the nested dictionary\n",
    "                    if epoch not in aux_losses:\n",
    "                        aux_losses[epoch] = {}\n",
    "                    \n",
    "                    aux_losses[epoch][step] = batch_aux_loss\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return aux_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cad38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_batch_losses(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract batch_loss for each epoch and step.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary of the form: {epoch: {step: batch_loss}}\n",
    "    \"\"\"\n",
    "    # Regex is adjusted to capture 'batch_loss'\n",
    "    # Note: 'batch_loss' appears before other metrics, so the regex handles this.\n",
    "    log_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+, step: (\\d+)/\\d+ .*?batch_loss: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    batch_losses = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                match = log_pattern.search(line)\n",
    "                if match:\n",
    "                    # Extract captured groups\n",
    "                    epoch = int(match.group(1))\n",
    "                    step = int(match.group(2))\n",
    "                    batch_loss = float(match.group(3))\n",
    "\n",
    "                    # Populate the nested dictionary\n",
    "                    if epoch not in batch_losses:\n",
    "                        batch_losses[epoch] = {}\n",
    "                    \n",
    "                    batch_losses[epoch][step] = batch_loss\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return batch_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235d99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_mIoU(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract batch_mIoU for each epoch and step.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A nested dictionary of the form: {epoch: {step: mIoU}}\n",
    "    \"\"\"\n",
    "    # Regex is adjusted to capture 'batch_mIoU'\n",
    "    log_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+, step: (\\d+)/\\d+ .*?batch_mIoU: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    miou_scores = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                match = log_pattern.search(line)\n",
    "                if match:\n",
    "                    # Extract captured groups\n",
    "                    epoch = int(match.group(1))\n",
    "                    step = int(match.group(2))\n",
    "                    batch_mIoU = float(match.group(3))\n",
    "\n",
    "                    # Populate the nested dictionary\n",
    "                    if epoch not in miou_scores:\n",
    "                        miou_scores[epoch] = {}\n",
    "                    \n",
    "                    miou_scores[epoch][step] = batch_mIoU\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return miou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2a4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_val_accuracies(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract validation accuracies for each epoch.\n",
    "\n",
    "    It handles two cases:\n",
    "    1. The initial validation before training starts, assigned to epoch 0.\n",
    "    2. End-of-epoch validations, assigned to their corresponding epoch number.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping epoch number to validation accuracy.\n",
    "        Example: {0: 0.8989, 1: 0.9150, 2: 0.9230}\n",
    "    \"\"\"\n",
    "    # Pattern for the initial validation line (before epoch 1)\n",
    "    initial_val_pattern = re.compile(\n",
    "        r\"\\[Before any weight update, VALIDATION\\].*?val_acc: ([\\d.]+)\"\n",
    "    )\n",
    "    \n",
    "    # Pattern for end-of-epoch validation lines (assumes a similar format)\n",
    "    epoch_val_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+.*?VALIDATION\\].*?val_acc: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    val_accuracies = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                # First, check for the initial validation line\n",
    "                initial_match = initial_val_pattern.search(line)\n",
    "                if initial_match:\n",
    "                    val_acc = float(initial_match.group(1))\n",
    "                    val_accuracies[0] = val_acc\n",
    "                    continue # Move to the next line\n",
    "\n",
    "                # If not initial, check for a standard end-of-epoch validation line\n",
    "                epoch_match = epoch_val_pattern.search(line)\n",
    "                if epoch_match:\n",
    "                    epoch = int(epoch_match.group(1))\n",
    "                    val_acc = float(epoch_match.group(2))\n",
    "                    val_accuracies[epoch] = val_acc\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f388edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_val_losses(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract validation losses for each epoch.\n",
    "\n",
    "    It handles two cases:\n",
    "    1. The initial validation before training starts, assigned to epoch 0.\n",
    "    2. End-of-epoch validations, assigned to their corresponding epoch number.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping epoch number to validation loss.\n",
    "        Example: {0: 0.3772, 1: 0.2510, 2: 0.2300}\n",
    "    \"\"\"\n",
    "    # Pattern for the initial validation line (before epoch 1)\n",
    "    initial_val_pattern = re.compile(\n",
    "        r\"\\[Before any weight update, VALIDATION\\].*?val_loss: ([\\d.]+)\"\n",
    "    )\n",
    "    \n",
    "    # Pattern for end-of-epoch validation lines\n",
    "    epoch_val_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+.*?VALIDATION\\].*?val_loss: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    val_losses = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                # First, check for the initial validation line\n",
    "                initial_match = initial_val_pattern.search(line)\n",
    "                if initial_match:\n",
    "                    val_loss = float(initial_match.group(1))\n",
    "                    val_losses[0] = val_loss\n",
    "                    continue # Move to the next line\n",
    "\n",
    "                # If not initial, check for a standard end-of-epoch validation line\n",
    "                epoch_match = epoch_val_pattern.search(line)\n",
    "                if epoch_match:\n",
    "                    epoch = int(epoch_match.group(1))\n",
    "                    val_loss = float(epoch_match.group(2))\n",
    "                    val_losses[epoch] = val_loss\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2eecbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_val_mIoU(filepath: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses a log file to extract validation mIoU scores for each epoch.\n",
    "\n",
    "    It handles two cases:\n",
    "    1. The initial validation before training starts, assigned to epoch 0.\n",
    "    2. End-of-epoch validations, assigned to their corresponding epoch number.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to the .log file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping epoch number to validation mIoU.\n",
    "        Example: {0: 0.6055, 1: 0.6870, 2: 0.7120}\n",
    "    \"\"\"\n",
    "    # Pattern for the initial validation line (before epoch 1)\n",
    "    initial_val_pattern = re.compile(\n",
    "        r\"\\[Before any weight update, VALIDATION\\].*?val_mIoU: ([\\d.]+)\"\n",
    "    )\n",
    "    \n",
    "    # Pattern for end-of-epoch validation lines\n",
    "    epoch_val_pattern = re.compile(\n",
    "        r\"\\[epoch: (\\d+)/\\d+.*?VALIDATION\\].*?val_mIoU: ([\\d.]+)\"\n",
    "    )\n",
    "\n",
    "    val_miou_scores = {}\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                # First, check for the initial validation line\n",
    "                initial_match = initial_val_pattern.search(line)\n",
    "                if initial_match:\n",
    "                    val_miou = float(initial_match.group(1))\n",
    "                    val_miou_scores[0] = val_miou\n",
    "                    continue # Move to the next line\n",
    "\n",
    "                # If not initial, check for a standard end-of-epoch validation line\n",
    "                epoch_match = epoch_val_pattern.search(line)\n",
    "                if epoch_match:\n",
    "                    epoch = int(epoch_match.group(1))\n",
    "                    val_miou = float(epoch_match.group(2))\n",
    "                    val_miou_scores[epoch] = val_miou\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filepath}' was not found.\")\n",
    "        return {}\n",
    "        \n",
    "    return val_miou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c29297",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs = parse_log_accuracies('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')\n",
    "train_aux_losses = parse_log_aux_losses('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')\n",
    "train_losses = parse_log_batch_losses('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')\n",
    "train_mIoU = parse_log_mIoU('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a149aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logs_dir_path = '/home/olivieri/exp/logs_tb/seg/with_text'\n",
    "exp_name = 'phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08c4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_exp_dir = os.path.join(tb_logs_dir_path, exp_name)\n",
    "os.makedirs(tb_exp_dir, exist_ok=True)\n",
    "tb_writer = SummaryWriter(log_dir=tb_exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9b84cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_values in train_accs.items():\n",
    "    for s, step_value in step_values.items():\n",
    "        tb_writer.add_scalar(f\"train/acc\", step_value, (e-1)*46 + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137d6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_values in train_aux_losses.items():\n",
    "    for s, step_value in step_values.items():\n",
    "        tb_writer.add_scalar(f\"train/aux_loss\", step_value, (e-1)*46 + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba731a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_values in train_losses.items():\n",
    "    for s, step_value in step_values.items():\n",
    "        tb_writer.add_scalar(f\"train/loss\", step_value, (e-1)*46 + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba2f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_values in train_mIoU.items():\n",
    "    for s, step_value in step_values.items():\n",
    "        tb_writer.add_scalar(f\"train/mIoU\", step_value, (e-1)*46 + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84a55c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs = parse_log_val_accuracies('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')\n",
    "val_losses = parse_log_val_losses('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')\n",
    "val_mIoU = parse_log_val_mIoU('/home/olivieri/exp/logs/seg/with_text/synth_contr/phase_3_vlm_text_from-e5_alpha0.1_250903_2007.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1991af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_value in val_accs.items():\n",
    "    tb_writer.add_scalar(f\"val/acc\", step_value, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec75444",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_value in val_losses.items():\n",
    "    tb_writer.add_scalar(f\"val/loss\", step_value, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac6b95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, step_value in val_mIoU.items():\n",
    "    tb_writer.add_scalar(f\"val/mIoU\", step_value, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "806629da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
