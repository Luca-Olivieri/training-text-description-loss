{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30b6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1360c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.config import *\n",
    "\n",
    "from core.datasets import VOC2012SegDataset\n",
    "from core.data import crop_augment_preprocess_batch\n",
    "from core.data_utils import flatten_list_of_lists\n",
    "from core.color_map import apply_colormap\n",
    "from core.torch_utils import get_activation\n",
    "from models.seg import (SEGMODELS_REGISTRY,\n",
    "    compute_seg_grad_cam, \n",
    "    compute_seg_grad_cam_pp,\n",
    "    compute_seg_xgrad_cam,\n",
    "    compute_seg_xres_cam,\n",
    "    compute_seg_hires_grad_cam)\n",
    "from core.viz import normalize_sim_maps, viz_seg_saliency_maps\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.transforms._presets import SemanticSegmentation\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.utils.hooks import RemovableHandle\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassJaccardIndex\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88ae40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = setup_config(BASE_CONFIG, Path('/home/olivieri/exp/src/eval/seg/config.yml'))\n",
    "seg_config = config['seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmodel = SEGMODELS_REGISTRY.get(\n",
    "    name=seg_config['model_name'],\n",
    "    pretrained_weights_path=seg_config['pretrained_weights_path'],\n",
    "    device=config['device'],\n",
    "    adaptation=seg_config['adaptation']\n",
    ")\n",
    "segmodel.adapt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3810cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_config['checkpoint_path']:\n",
    "    state_dict: OrderedDict = torch.load(seg_config['checkpoint_path'], map_location='cpu')\n",
    "    model_state_dict = state_dict.get('model_state_dict', state_dict)\n",
    "    segmodel.model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f78802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VOC2012SegDataset(\n",
    "    root_path=config['datasets']['VOC2012_root_path'],\n",
    "    split='train',\n",
    "    device=config['device'],\n",
    "    resize_size=seg_config['image_size'],\n",
    "    center_crop=False,\n",
    "    with_unlabelled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd3fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = VOC2012SegDataset(\n",
    "    root_path=config['datasets']['VOC2012_root_path'],\n",
    "    split='val',\n",
    "    device=config['device'],\n",
    "    resize_size=seg_config['image_size'],\n",
    "    center_crop=False,\n",
    "    with_unlabelled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a25f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = partial(\n",
    "    crop_augment_preprocess_batch,\n",
    "    crop_fn=T.CenterCrop(seg_config['image_size']),\n",
    "    augment_fn=None,\n",
    "    preprocess_fn=segmodel.preprocess_images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a749a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=seg_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    generator=get_torch_gen(),\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0657cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=seg_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    generator=get_torch_gen(),\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2533bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304642d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    \"acc\": MulticlassAccuracy(num_classes=val_ds.get_num_classes(with_unlabelled=True), top_k=1, average='micro', multidim_average='global', ignore_index=21).to(config['device']),\n",
    "    \"mIoU\": MulticlassJaccardIndex(num_classes=val_ds.get_num_classes(with_unlabelled=True), average='none', ignore_index=21).to(config['device']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0576953",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_metrics_score = segmodel.evaluate(train_dl, criterion, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5711cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8063, device='cuda:0'),\n",
       " tensor([0.9524, 0.8641, 0.3496, 0.8926, 0.8507, 0.7918, 0.9279, 0.8923, 0.9344,\n",
       "         0.4818, 0.7928, 0.7926, 0.8969, 0.8264, 0.8148, 0.8644, 0.6714, 0.8973,\n",
       "         0.6833, 0.9207, 0.8340, 0.0000], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mIoU = train_metrics_score['mIoU']\n",
    "train_mIoU[:21].mean(), train_mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16cbb128",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_metrics_score = segmodel.evaluate(val_dl, criterion, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af7da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5503, device='cuda:0'),\n",
       " tensor([0.8921, 0.7252, 0.2802, 0.7397, 0.5178, 0.5451, 0.7730, 0.7079, 0.7107,\n",
       "         0.1638, 0.4484, 0.3785, 0.5951, 0.4532, 0.6296, 0.7469, 0.2850, 0.4735,\n",
       "         0.3419, 0.6312, 0.5168, 0.0000], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mIoU = val_metrics_score['mIoU']\n",
    "mIoU[:21].mean(), mIoU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
