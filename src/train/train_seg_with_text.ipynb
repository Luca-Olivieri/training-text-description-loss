{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c93122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79c46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from data import VOC2012SegDataset, crop_augment_preprocess_batch\n",
    "from models.seg_models import evaluate, set_trainable_params\n",
    "from models.vl_models import GenParams, OllamaMLLM\n",
    "from models.vl_encoders import VLE_REGISTRY, VLEncoder\n",
    "from prompter import FastPromptBuilder\n",
    "from logger import LogManager\n",
    "from path import get_mask_prs_path\n",
    "from viz import get_layer_numel_str\n",
    "from utils import clear_memory, get_activation\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import segmentation as segmodels\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms._presets import SemanticSegmentation\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassJaccardIndex\n",
    "import torchmetrics as tm\n",
    "from open_clip_train.scheduler import cosine_lr, const_lr, const_lr_cooldown\n",
    "from open_clip.loss import SigLipLoss, ClipLoss\n",
    "import math\n",
    "\n",
    "from typing import Optional\n",
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2befd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEG_CONFIG = CONFIG['seg']\n",
    "SEG_TRAIN_CONFIG = SEG_CONFIG['train']\n",
    "\n",
    "VLE_CONFIG = CONFIG['vle']\n",
    "VLE_TRAIN_CONFIG = VLE_CONFIG['train']\n",
    "\n",
    "if SEG_TRAIN_CONFIG['log_only_to_stdout']:\n",
    "    log_manager = LogManager(\n",
    "        exp_name=SEG_TRAIN_CONFIG['exp_name'],\n",
    "        exp_desc=SEG_TRAIN_CONFIG['exp_desc'],\n",
    "    )\n",
    "else:\n",
    "    log_manager = LogManager(\n",
    "        exp_name=SEG_TRAIN_CONFIG['exp_name'],\n",
    "        exp_desc=SEG_TRAIN_CONFIG['exp_desc'],\n",
    "        file_logs_dir_path=SEG_TRAIN_CONFIG['file_logs_dir_path'],\n",
    "        tb_logs_dir_path=SEG_TRAIN_CONFIG['tb_logs_dir_path']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bafcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train_loop(\n",
    "        segnet: nn.Module,\n",
    "        vlm: OllamaMLLM,\n",
    "        vle: VLEncoder,\n",
    "        train_dl: DataLoader,\n",
    "        val_dl: DataLoader,\n",
    "        fast_prompt_builder: FastPromptBuilder,\n",
    "        seg_preprocess_fn: nn.Module,\n",
    "        gen_params: GenParams,\n",
    "        criterion: _Loss,\n",
    "        contr_criterion: nn.Module,\n",
    "        metrics_dict: dict[dict, tm.Metric],\n",
    "        checkpoint_dict: Optional[dict] = None\n",
    ") -> None:\n",
    "    \n",
    "    # --- 1. Initialization and State Restoration ---\n",
    "    start_epoch = 0\n",
    "    global_step = 0\n",
    "    if checkpoint_dict:\n",
    "        start_epoch = checkpoint_dict['epoch'] + 1\n",
    "        global_step = checkpoint_dict['global_step']\n",
    "        log_manager.log_line(f\"Resuming training from epoch {start_epoch}, global step {global_step}.\")\n",
    "\n",
    "    grad_accum_steps = SEG_TRAIN_CONFIG['grad_accum_steps']\n",
    "    num_batches_per_epoch = len(train_dl)\n",
    "    # The number of optimizer steps per epoch\n",
    "    num_steps_per_epoch = math.ceil(num_batches_per_epoch / grad_accum_steps)\n",
    "\n",
    "    # --- 2. Optimizer Setup ---\n",
    "    lr=SEG_TRAIN_CONFIG['lr_schedule']['base_lr']\n",
    "    optimizer = torch.optim.AdamW(segnet.parameters(), lr=lr)\n",
    "    if checkpoint_dict:\n",
    "        optimizer.load_state_dict(checkpoint_dict['optimizer_state_dict'])\n",
    "\n",
    "    # --- 3. Scheduler Setup ---\n",
    "    total_steps = num_steps_per_epoch * SEG_TRAIN_CONFIG['num_epochs']\n",
    "    sched_config = SEG_TRAIN_CONFIG['lr_schedule']\n",
    "    \n",
    "    scheduler = None\n",
    "    if sched_config['policy'] == 'const':\n",
    "        scheduler = const_lr(optimizer, sched_config['base_lr'], sched_config['warmup_length'], total_steps)\n",
    "    elif sched_config['policy'] == 'const-cooldown':\n",
    "        cooldown_steps = num_steps_per_epoch * sched_config['epochs_cooldown']\n",
    "        scheduler = const_lr_cooldown(optimizer, sched_config['base_lr'], sched_config['warmup_length'], total_steps, cooldown_steps, sched_config['lr_cooldown_power'], sched_config['lr_cooldown_end'])\n",
    "    elif sched_config['policy'] == 'cosine':\n",
    "        scheduler = cosine_lr(optimizer, sched_config['base_lr'], sched_config['warmup_length'], total_steps)\n",
    "\n",
    "    # --- 4. AMP and Model Compilation Setup ---\n",
    "    ...\n",
    "\n",
    "    # --- 5. Initial Validation ---\n",
    "    log_manager.log_title(\"Initial Validation\")\n",
    "    val_loss, val_metrics_score = evaluate(segnet, val_dl, criterion, metrics_dict)\n",
    "    log_manager.log_scores(f\"Before any weight update, VALIDATION\", val_loss, val_metrics_score, start_epoch, \"val\", None, \"val_\")\n",
    "    best_val_mIoU = val_metrics_score['mIoU']\n",
    "\n",
    "    log_manager.log_title(\"Training Start\")\n",
    "    \n",
    "    # --- 6. Main Training Loop ---\n",
    "    train_metrics = tm.MetricCollection(metrics_dict)\n",
    "    for epoch in range(start_epoch, SEG_TRAIN_CONFIG[\"num_epochs\"]):\n",
    "\n",
    "        train_metrics.reset() # in theory, this can be removed\n",
    "\n",
    "        for step, (scs_img, gts) in enumerate(train_dl):\n",
    "\n",
    "            # --- Seg --- #\n",
    "\n",
    "            segnet.train()\n",
    "\n",
    "            scs = seg_preprocess_fn(scs_img)\n",
    "\n",
    "            scs = scs.to(CONFIG[\"device\"])\n",
    "            gts = gts.to(CONFIG[\"device\"]) # shape [B, H, W]\n",
    "            \n",
    "            logits = segnet(scs)\n",
    "            logits: torch.Tensor = logits[\"out\"] if isinstance(logits, OrderedDict) else logits #Â shape [N, C, H, W]\n",
    "            \n",
    "            train_metrics.update(logits.detach().argmax(dim=1), gts)\n",
    "\n",
    "            seg_batch_loss: torch.Tensor = criterion(logits, gts) / grad_accum_steps\n",
    "\n",
    "            if True:\n",
    "\n",
    "                # --- VLM --- #\n",
    "\n",
    "                scs_img = (scs_img*255).to(torch.uint8)\n",
    "                gts = gts.unsqueeze(1)\n",
    "                prs = logits.argmax(dim=1, keepdim=True)\n",
    "                # Both VLM and VLE receive the images in the same downsampled size.\n",
    "                gts_down = TF.resize(gts, fast_prompt_builder.image_size, TF.InterpolationMode.NEAREST)\n",
    "                prs_down = TF.resize(prs, fast_prompt_builder.image_size, TF.InterpolationMode.NEAREST)\n",
    "                scs_down = TF.resize(scs_img, fast_prompt_builder.image_size, TF.InterpolationMode.BILINEAR)\n",
    "                cs_prompts = fast_prompt_builder.build_cs_inference_prompts(gts_down, prs_down, scs_down)\n",
    "\n",
    "                batch_idxs = [train_dl.batch_size*step + i for i in range(len(scs_down))]\n",
    "                \n",
    "                cs_answer_list = await vlm.predict_many_class_splitted(\n",
    "                    cs_prompts,\n",
    "                    batch_idxs,\n",
    "                    gen_params=gen_params,\n",
    "                    jsonl_save_path=None,\n",
    "                    only_text=True,\n",
    "                    splits_in_parallel=False,\n",
    "                    batch_size=None,\n",
    "                    use_tqdm=False\n",
    "                )\n",
    "\n",
    "                # --- VLE --- #\n",
    "\n",
    "                global_text_tokens = list()\n",
    "                for i, img_idx in enumerate(batch_idxs):\n",
    "                    # cs_texts = [text for pos_, text in cs_answer_list[i]['content'].items()]\n",
    "                    cs_texts = list(cs_answer_list[i]['content'].values()) # gather the text for each pos. class of this image\n",
    "                    cs_texts = vle.preprocess_texts(cs_texts)\n",
    "                    cs_vle_output = vle.encode_and_project(images=None, texts=cs_texts, broadcast=False)\n",
    "\n",
    "                    global_text_token = cs_vle_output.global_text_token\n",
    "                    aggr_global_text_token = torch.max(global_text_token, dim=0).values # aggregating the class-splitted text vectors with a MaxPool.\n",
    "                    global_text_tokens.append(aggr_global_text_token)\n",
    "\n",
    "                global_text_tokens = torch.stack(global_text_tokens)\n",
    "\n",
    "                # global_text_tokens = global_text_tokens @ torch.rand(size=(512, 960), device=global_text_tokens.device) # TODO here the 'global_text_tokens' have to be processed again before the additional loss\n",
    "                global_text_tokens = global_text_tokens @ torch.zeros(size=(512, 960), device=global_text_tokens.device) # TODO here the 'global_text_tokens' have to be processed again before the additional loss\n",
    "                \n",
    "                bottleneck_out: torch.Tensor = segnet.backbone['16'].activations['bottleneck']\n",
    "                bottleneck_vec = segnet.backbone.gap(bottleneck_out).squeeze()\n",
    "                \n",
    "                contr_batch_loss = contr_criterion(\n",
    "                    image_features=bottleneck_vec,\n",
    "                    text_features=global_text_tokens,\n",
    "                    logit_scale=vle.model.logit_scale/vle.model.logit_scale,\n",
    "                    logit_bias=vle.model.logit_bias*0,\n",
    "                    output_dict=False\n",
    "                )\n",
    "                \n",
    "                batch_loss: torch.Tensor = seg_batch_loss + SEG_TRAIN_CONFIG['with_text']['loss_lam']*contr_batch_loss # multi-task loss\n",
    "            else:\n",
    "                batch_loss = seg_batch_loss\n",
    "\n",
    "            batch_loss.backward()\n",
    "\n",
    "            print(f\"{step=}, {batch_loss=}\")\n",
    "\n",
    "            is_last_batch = (step + 1) == num_batches_per_epoch\n",
    "            is_accum_step = (step + 1) % grad_accum_steps == 0\n",
    "\n",
    "            # --- Optimizer Step and Scheduler Update ---\n",
    "            if is_accum_step or is_last_batch:\n",
    "                \n",
    "                if scheduler:\n",
    "                    scheduler(global_step)\n",
    "\n",
    "                max_grad_norm = SEG_TRAIN_CONFIG['grad_clip_norm']\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    segnet.parameters(),\n",
    "                    max_grad_norm if max_grad_norm else float('inf'),\n",
    "                    norm_type=2.0\n",
    "                )\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                global_step += 1 # Increment global step *only* after an optimizer step\n",
    "\n",
    "                # --- Logging ---\n",
    "                if global_step % SEG_TRAIN_CONFIG['log_every'] == 0:\n",
    "                    train_metrics_score = train_metrics.compute()                    \n",
    "                    current_lr = optimizer.param_groups[0]['lr']\n",
    "                    step_in_epoch = (step // grad_accum_steps) + 1\n",
    "                    log_manager.log_scores(\n",
    "                        f\"epoch: {epoch+1}/{SEG_TRAIN_CONFIG['num_epochs']}, step: {step_in_epoch}/{num_steps_per_epoch} (global_step: {global_step})\",\n",
    "                        batch_loss * grad_accum_steps, train_metrics_score, global_step, \"train\",\n",
    "                        f\", lr: {current_lr:.2e}, grad_norm: {grad_norm:.2f}\", \"batch_\"\n",
    "                    )\n",
    "\n",
    "                train_metrics.reset() # only the batch metrics are logged\n",
    "\n",
    "            #Â torch.cuda.synchronize() if CONFIG['device'] == 'cuda' else None\n",
    "\n",
    "        # --- End of Epoch Validation and Checkpointing ---\n",
    "        val_loss, val_metrics_score = evaluate(segnet, val_dl, criterion, metrics_dict)\n",
    "        log_manager.log_scores(f\"epoch: {epoch+1}/{SEG_TRAIN_CONFIG['num_epochs']}, VALIDATION\", val_loss, val_metrics_score, epoch+1, \"val\", None, \"val_\")\n",
    "\n",
    "        if val_metrics_score['mIoU'] > best_val_mIoU:\n",
    "            best_val_mIoU = val_metrics_score['mIoU']\n",
    "            \n",
    "            if SEG_TRAIN_CONFIG['save_weights_root_path']:\n",
    "                # Note: 'epoch' is saved, so on resume we start from 'epoch + 1'\n",
    "                new_checkpoint_dict = {\n",
    "                    'epoch': epoch,\n",
    "                    'global_step': global_step,\n",
    "                    'model_state_dict': segnet.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }\n",
    "\n",
    "                save_dir = Path(SEG_TRAIN_CONFIG['save_weights_root_path'])\n",
    "                save_dir.mkdir(parents=True, exist_ok=True)\n",
    "                ckp_filename = f\"lraspp_mobilenet_v3_large_{SEG_TRAIN_CONFIG['exp_name']}.pth\"\n",
    "                full_ckp_path = save_dir / ckp_filename\n",
    "                torch.save(new_checkpoint_dict, full_ckp_path)\n",
    "                log_manager.log_line(f\"New best model saved to {full_ckp_path} with validation mIoU: {best_val_mIoU:.4f}\")\n",
    "    \n",
    "    log_manager.log_title(\"Training Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VOC2012SegDataset(\n",
    "    root_path=Path(\"/home/olivieri/exp/data/VOCdevkit\"),\n",
    "    split='train',\n",
    "    resize_size=SEG_CONFIG['image_size'],\n",
    "    center_crop=True,\n",
    "    with_unlabelled=True,\n",
    ")\n",
    "\n",
    "val_ds = VOC2012SegDataset(\n",
    "    root_path=Path(\"/home/olivieri/exp/data/VOCdevkit\"),\n",
    "    split='val',\n",
    "    resize_size=SEG_CONFIG['image_size'],\n",
    "    center_crop=True,\n",
    "    with_unlabelled=True,\n",
    "    img_idxs=slice(None, 20, None) # TODO remove to have full val. dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0a4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation Model\n",
    "segnet = segmodels.lraspp_mobilenet_v3_large(weights=None, weights_backbone=None).to(CONFIG[\"device\"])\n",
    "segnet.load_state_dict(torch.load(Path(SEG_CONFIG['pretrained_weights_root_path']) / (\"lraspp_mobilenet_v3_large-full-pt\" + \".pth\")))\n",
    "# TODO to modify with the actual segnet intermediate checkpoint\n",
    "segnet.eval()\n",
    "\n",
    "checkpoint_dict = None\n",
    "if SEG_TRAIN_CONFIG['resume_path']:\n",
    "    vle_weights_path = Path(SEG_TRAIN_CONFIG['resume_path'])\n",
    "    if vle_weights_path.exists():\n",
    "        checkpoint_dict = torch.load(vle_weights_path, map_location=CONFIG['device'])\n",
    "        segnet.load_state_dict(checkpoint_dict['model_state_dict'])\n",
    "    else:\n",
    "        raise AttributeError(f\"ERROR: Resume path '{vle_weights_path}' not found. \")\n",
    "\n",
    "bottleneck_gap = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "segnet.backbone.add_module('gap', bottleneck_gap)\n",
    "\n",
    "set_trainable_params(segnet, train_decoder_only=SEG_TRAIN_CONFIG['train_decoder_only'])\n",
    "\n",
    "\n",
    "# NOTE should I clone the fw hook output?\n",
    "# register the forward hook to store the bottleneck output.\n",
    "target_layer = segnet.backbone['16'] # [960, 32, 32] bottleneck output\n",
    "target_layer.activations = dict() # to store the fw hooks output\n",
    "handle = target_layer.register_forward_hook(get_activation('bottleneck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4aec30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-Language Model\n",
    "model_name = \"gemma3:12b-it-qat\"\n",
    "vlm = OllamaMLLM(model_name)\n",
    "\n",
    "by_model = \"LRASPP_MobileNet_V3\"\n",
    "\n",
    "gen_params = GenParams(\n",
    "    seed=CONFIG[\"seed\"],\n",
    "    temperature=SEG_TRAIN_CONFIG['with_text']['vlm_temperature'],\n",
    ")\n",
    "\n",
    "prompt_blueprint={\n",
    "        \"context\": \"default\",\n",
    "        \"color_map\": \"default\",\n",
    "        \"input_format\": \"sep_ovr_original\",\n",
    "        \"task\": \"default\",\n",
    "        \"output_format\": \"default\",\n",
    "        \"support_set_intro\": \"default\",\n",
    "        \"support_set_item\": \"default\",\n",
    "        \"query\": \"default\",\n",
    "}\n",
    "\n",
    "# NOTE when used in this pipeline, the dataset is useful only to access class maps and color maps, the actual data is not retrieved from here.\n",
    "seg_dataset = VOC2012SegDataset(\n",
    "    root_path=Path(CONFIG['datasets']['VOC2012_root_path']),\n",
    "    split='train',\n",
    "    resize_size=CONFIG['seg']['image_size'],\n",
    "    center_crop=True,\n",
    "    with_unlabelled=False,\n",
    ")\n",
    "\n",
    "sup_set_seg_dataset = VOC2012SegDataset(\n",
    "    root_path=Path(CONFIG['datasets']['VOC2012_root_path']),\n",
    "    split='prompts_split',\n",
    "    resize_size=CONFIG['seg']['image_size'],\n",
    "    center_crop=True,\n",
    "    with_unlabelled=False,\n",
    "    mask_prs_path=get_mask_prs_path(by_model=by_model)\n",
    ")\n",
    "\n",
    "fast_prompt_builder = FastPromptBuilder(\n",
    "    seg_dataset=seg_dataset,\n",
    "    seed=CONFIG[\"seed\"],\n",
    "    prompt_blueprint=prompt_blueprint,\n",
    "    by_model=by_model,\n",
    "    alpha=0.6,\n",
    "    class_map=seg_dataset.get_class_map(with_unlabelled=False),\n",
    "    color_map=seg_dataset.get_color_map_dict(with_unlabelled=False),\n",
    "    image_size=CONFIG['vlm']['image_size'],\n",
    "    sup_set_img_idxs=[16],\n",
    "    sup_set_seg_dataset=sup_set_seg_dataset,\n",
    "    str_formats=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8f032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-Language Encoder\n",
    "vle: VLEncoder = VLE_REGISTRY.get(\"flair\", version='flair-cc3m-recap.pt', device=CONFIG['device'], vision_adapter=False, text_adapter=False)\n",
    "vle_weights_path = Path(SEG_TRAIN_CONFIG['with_text']['vle_weights_path'])\n",
    "if vle_weights_path.exists():\n",
    "    vle.model.load_state_dict(torch.load(vle_weights_path, map_location=CONFIG['device'])['model_state_dict'])\n",
    "else:\n",
    "    raise AttributeError(f\"ERROR: VLE weights path '{vle_weights_path}' not found.\")\n",
    "\n",
    "vle.set_vision_trainable_params()\n",
    "\n",
    "# NOTE deleting vision layers only if encoding text only.\n",
    "del vle.model.visual, vle.model.visual_proj, vle.model.image_post\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a52989d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "contr_criterion = SigLipLoss() #  NOTE or should I use FLAIRLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a909fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_protocol = '...'\n",
    "\n",
    "if text_protocol == 'contrastive_global':\n",
    "    ...\n",
    "if text_protocol == 'contrastive_local':\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd04b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-07-31 15:26:45,027 INFO 3511189400.py line 51] ====================================[ test_no_text_250731_1526 ]====================================\n",
      "[2025-07-31 15:26:45,029 INFO 3511189400.py line 51] ---------------------------------------------[ Config ]---------------------------------------------\n",
      "[2025-07-31 15:26:45,030 INFO 3511189400.py line 51] {'seed': 42, 'device': 'cuda', 'datasets': {'COCO2017_root_path': '/home/olivieri/exp/shared_data/coco2017', 'VOC2012_root_path': '/home/olivieri/exp/data/VOCdevkit'}, 'seg': {'pretrained_weights_root_path': '/home/olivieri/exp/data/torch_weights/seg/lraspp_mobilenet_v3_large/no_text', 'image_size': 520, 'train': {'exp_name': 'test_no_text_250731_1526', 'exp_desc': '', 'train_decoder_only': False, 'batch_size': 8, 'num_epochs': 50, 'lr_schedule': {'policy': 'cosine', 'base_lr': 0.0001, 'warmup_length': 200, 'epochs_cooldown': None, 'lr_cooldown_power': None, 'lr_cooldown_end': None}, 'grad_clip_norm': 10.0, 'grad_accum_steps': 1, 'resume_path': None, 'log_only_to_stdout': False, 'file_logs_dir_path': '/home/olivieri/exp/logs/seg/with_text', 'tb_logs_dir_path': '/home/olivieri/exp/logs_tb/seg/with_text', 'log_every': 10, 'save_weights_root_path': '/home/olivieri/exp/data/torch_weights/seg/lraspp_mobilenet_v3_large/with_text', 'with_text': {'vle_weights_path': '/home/olivieri/exp/data/torch_weights/vle/flair/flair-flair-cc3m-recap.pt-image_proj_L_250730_1824.pth', 'vlm_temperature': 0.1, 'loss_lam': 1.0}}}, 'vle': {'pretrained_weights_root_path': '/home/olivieri/exp/data/torch_weights/vle/flair', 'image_size': 224, 'train': {'exp_name': 'visual_proj_N_250731_1526', 'exp_desc': 'Training visual_proj, N masks, with the cc3m-recap pretraining.', 'batch_size': 256, 'num_epochs': 16, 'mask_color': 'L', 'precision': 'amp_bfloat16', 'lr_schedule': {'policy': 'cosine', 'base_lr': 0.0005, 'warmup_length': 100, 'epochs_cooldown': None, 'lr_cooldown_power': None, 'lr_cooldown_end': None}, 'grad_clip_norm': 10.0, 'grad_accum_steps': 1, 'resume_path': None, 'log_only_to_stdout': False, 'file_logs_dir_path': '/home/olivieri/exp/logs/vle', 'tb_logs_dir_path': '/home/olivieri/exp/logs_tb/vle', 'log_every': 10, 'save_weights_root_path': '/home/olivieri/exp/data/torch_weights/vle/flair'}}, 'vlm': {'image_size': 224, 'alpha': 0.6, 'sup_set_img_idxs': [16], 'temperature': 0.1}, 'data_gen': {'data_root': '/home/olivieri/exp/data/data_gen/COCO2017', 'exp_name': 'l2_train', 'batch_size': 1, 'offset': 34098, 'alpha': 0.55, 'print_every': 100, 'temperature': 0.7, 'top_p': None}}\n",
      "[2025-07-31 15:26:45,031 INFO 3511189400.py line 51] ----------------------------------------------[ Data ]----------------------------------------------\n",
      "[2025-07-31 15:26:45,035 INFO 3511189400.py line 51] - Training data: 1464 samples, in 183 mini-batches of size 8\n",
      "[2025-07-31 15:26:45,041 INFO 3511189400.py line 51] - Validation data: 20 samples, in 3 mini-batches of size 8\n",
      "[2025-07-31 15:26:45,042 INFO 3511189400.py line 60] ----------------------------------------[ Trainable Params ]----------------------------------------\n",
      "[2025-07-31 15:26:45,045 INFO 3511189400.py line 61] backbone.0.0.weight               : 432\n",
      "[2025-07-31 15:26:45,045 INFO 3511189400.py line 61] backbone.0.1.weight               : 16\n",
      "[2025-07-31 15:26:45,047 INFO 3511189400.py line 61] backbone.0.1.bias                 : 16\n",
      "[2025-07-31 15:26:45,047 INFO 3511189400.py line 61] backbone.1.block.0.0.weight       : 144\n",
      "[2025-07-31 15:26:45,048 INFO 3511189400.py line 61] backbone.1.block.0.1.weight       : 16\n",
      "[2025-07-31 15:26:45,050 INFO 3511189400.py line 61] backbone.1.block.0.1.bias         : 16\n",
      "[2025-07-31 15:26:45,051 INFO 3511189400.py line 61] backbone.1.block.1.0.weight       : 256\n",
      "[2025-07-31 15:26:45,051 INFO 3511189400.py line 61] backbone.1.block.1.1.weight       : 16\n",
      "[2025-07-31 15:26:45,052 INFO 3511189400.py line 61] backbone.1.block.1.1.bias         : 16\n",
      "[2025-07-31 15:26:45,053 INFO 3511189400.py line 61] backbone.2.block.0.0.weight       : 1,024\n",
      "[2025-07-31 15:26:45,054 INFO 3511189400.py line 61] backbone.2.block.0.1.weight       : 64\n",
      "[2025-07-31 15:26:45,055 INFO 3511189400.py line 61] backbone.2.block.0.1.bias         : 64\n",
      "[2025-07-31 15:26:45,056 INFO 3511189400.py line 61] backbone.2.block.1.0.weight       : 576\n",
      "[2025-07-31 15:26:45,057 INFO 3511189400.py line 61] backbone.2.block.1.1.weight       : 64\n",
      "[2025-07-31 15:26:45,057 INFO 3511189400.py line 61] backbone.2.block.1.1.bias         : 64\n",
      "[2025-07-31 15:26:45,059 INFO 3511189400.py line 61] backbone.2.block.2.0.weight       : 1,536\n",
      "[2025-07-31 15:26:45,059 INFO 3511189400.py line 61] backbone.2.block.2.1.weight       : 24\n",
      "[2025-07-31 15:26:45,060 INFO 3511189400.py line 61] backbone.2.block.2.1.bias         : 24\n",
      "[2025-07-31 15:26:45,061 INFO 3511189400.py line 61] backbone.3.block.0.0.weight       : 1,728\n",
      "[2025-07-31 15:26:45,061 INFO 3511189400.py line 61] backbone.3.block.0.1.weight       : 72\n",
      "[2025-07-31 15:26:45,062 INFO 3511189400.py line 61] backbone.3.block.0.1.bias         : 72\n",
      "[2025-07-31 15:26:45,063 INFO 3511189400.py line 61] backbone.3.block.1.0.weight       : 648\n",
      "[2025-07-31 15:26:45,064 INFO 3511189400.py line 61] backbone.3.block.1.1.weight       : 72\n",
      "[2025-07-31 15:26:45,065 INFO 3511189400.py line 61] backbone.3.block.1.1.bias         : 72\n",
      "[2025-07-31 15:26:45,066 INFO 3511189400.py line 61] backbone.3.block.2.0.weight       : 1,728\n",
      "[2025-07-31 15:26:45,066 INFO 3511189400.py line 61] backbone.3.block.2.1.weight       : 24\n",
      "[2025-07-31 15:26:45,067 INFO 3511189400.py line 61] backbone.3.block.2.1.bias         : 24\n",
      "[2025-07-31 15:26:45,068 INFO 3511189400.py line 61] backbone.4.block.0.0.weight       : 1,728\n",
      "[2025-07-31 15:26:45,069 INFO 3511189400.py line 61] backbone.4.block.0.1.weight       : 72\n",
      "[2025-07-31 15:26:45,070 INFO 3511189400.py line 61] backbone.4.block.0.1.bias         : 72\n",
      "[2025-07-31 15:26:45,071 INFO 3511189400.py line 61] backbone.4.block.1.0.weight       : 1,800\n",
      "[2025-07-31 15:26:45,071 INFO 3511189400.py line 61] backbone.4.block.1.1.weight       : 72\n",
      "[2025-07-31 15:26:45,073 INFO 3511189400.py line 61] backbone.4.block.1.1.bias         : 72\n",
      "[2025-07-31 15:26:45,073 INFO 3511189400.py line 61] backbone.4.block.2.fc1.weight     : 1,728\n",
      "[2025-07-31 15:26:45,074 INFO 3511189400.py line 61] backbone.4.block.2.fc1.bias       : 24\n",
      "[2025-07-31 15:26:45,075 INFO 3511189400.py line 61] backbone.4.block.2.fc2.weight     : 1,728\n",
      "[2025-07-31 15:26:45,076 INFO 3511189400.py line 61] backbone.4.block.2.fc2.bias       : 72\n",
      "[2025-07-31 15:26:45,076 INFO 3511189400.py line 61] backbone.4.block.3.0.weight       : 2,880\n",
      "[2025-07-31 15:26:45,077 INFO 3511189400.py line 61] backbone.4.block.3.1.weight       : 40\n",
      "[2025-07-31 15:26:45,078 INFO 3511189400.py line 61] backbone.4.block.3.1.bias         : 40\n",
      "[2025-07-31 15:26:45,079 INFO 3511189400.py line 61] backbone.5.block.0.0.weight       : 4,800\n",
      "[2025-07-31 15:26:45,080 INFO 3511189400.py line 61] backbone.5.block.0.1.weight       : 120\n",
      "[2025-07-31 15:26:45,081 INFO 3511189400.py line 61] backbone.5.block.0.1.bias         : 120\n",
      "[2025-07-31 15:26:45,082 INFO 3511189400.py line 61] backbone.5.block.1.0.weight       : 3,000\n",
      "[2025-07-31 15:26:45,083 INFO 3511189400.py line 61] backbone.5.block.1.1.weight       : 120\n",
      "[2025-07-31 15:26:45,084 INFO 3511189400.py line 61] backbone.5.block.1.1.bias         : 120\n",
      "[2025-07-31 15:26:45,085 INFO 3511189400.py line 61] backbone.5.block.2.fc1.weight     : 3,840\n",
      "[2025-07-31 15:26:45,086 INFO 3511189400.py line 61] backbone.5.block.2.fc1.bias       : 32\n",
      "[2025-07-31 15:26:45,087 INFO 3511189400.py line 61] backbone.5.block.2.fc2.weight     : 3,840\n",
      "[2025-07-31 15:26:45,088 INFO 3511189400.py line 61] backbone.5.block.2.fc2.bias       : 120\n",
      "[2025-07-31 15:26:45,088 INFO 3511189400.py line 61] backbone.5.block.3.0.weight       : 4,800\n",
      "[2025-07-31 15:26:45,089 INFO 3511189400.py line 61] backbone.5.block.3.1.weight       : 40\n",
      "[2025-07-31 15:26:45,090 INFO 3511189400.py line 61] backbone.5.block.3.1.bias         : 40\n",
      "[2025-07-31 15:26:45,091 INFO 3511189400.py line 61] backbone.6.block.0.0.weight       : 4,800\n",
      "[2025-07-31 15:26:45,092 INFO 3511189400.py line 61] backbone.6.block.0.1.weight       : 120\n",
      "[2025-07-31 15:26:45,093 INFO 3511189400.py line 61] backbone.6.block.0.1.bias         : 120\n",
      "[2025-07-31 15:26:45,094 INFO 3511189400.py line 61] backbone.6.block.1.0.weight       : 3,000\n",
      "[2025-07-31 15:26:45,095 INFO 3511189400.py line 61] backbone.6.block.1.1.weight       : 120\n",
      "[2025-07-31 15:26:45,096 INFO 3511189400.py line 61] backbone.6.block.1.1.bias         : 120\n",
      "[2025-07-31 15:26:45,097 INFO 3511189400.py line 61] backbone.6.block.2.fc1.weight     : 3,840\n",
      "[2025-07-31 15:26:45,097 INFO 3511189400.py line 61] backbone.6.block.2.fc1.bias       : 32\n",
      "[2025-07-31 15:26:45,098 INFO 3511189400.py line 61] backbone.6.block.2.fc2.weight     : 3,840\n",
      "[2025-07-31 15:26:45,099 INFO 3511189400.py line 61] backbone.6.block.2.fc2.bias       : 120\n",
      "[2025-07-31 15:26:45,100 INFO 3511189400.py line 61] backbone.6.block.3.0.weight       : 4,800\n",
      "[2025-07-31 15:26:45,101 INFO 3511189400.py line 61] backbone.6.block.3.1.weight       : 40\n",
      "[2025-07-31 15:26:45,102 INFO 3511189400.py line 61] backbone.6.block.3.1.bias         : 40\n",
      "[2025-07-31 15:26:45,103 INFO 3511189400.py line 61] backbone.7.block.0.0.weight       : 9,600\n",
      "[2025-07-31 15:26:45,103 INFO 3511189400.py line 61] backbone.7.block.0.1.weight       : 240\n",
      "[2025-07-31 15:26:45,104 INFO 3511189400.py line 61] backbone.7.block.0.1.bias         : 240\n",
      "[2025-07-31 15:26:45,105 INFO 3511189400.py line 61] backbone.7.block.1.0.weight       : 2,160\n",
      "[2025-07-31 15:26:45,106 INFO 3511189400.py line 61] backbone.7.block.1.1.weight       : 240\n",
      "[2025-07-31 15:26:45,107 INFO 3511189400.py line 61] backbone.7.block.1.1.bias         : 240\n",
      "[2025-07-31 15:26:45,108 INFO 3511189400.py line 61] backbone.7.block.2.0.weight       : 19,200\n",
      "[2025-07-31 15:26:45,109 INFO 3511189400.py line 61] backbone.7.block.2.1.weight       : 80\n",
      "[2025-07-31 15:26:45,110 INFO 3511189400.py line 61] backbone.7.block.2.1.bias         : 80\n",
      "[2025-07-31 15:26:45,111 INFO 3511189400.py line 61] backbone.8.block.0.0.weight       : 16,000\n",
      "[2025-07-31 15:26:45,113 INFO 3511189400.py line 61] backbone.8.block.0.1.weight       : 200\n",
      "[2025-07-31 15:26:45,114 INFO 3511189400.py line 61] backbone.8.block.0.1.bias         : 200\n",
      "[2025-07-31 15:26:45,115 INFO 3511189400.py line 61] backbone.8.block.1.0.weight       : 1,800\n",
      "[2025-07-31 15:26:45,117 INFO 3511189400.py line 61] backbone.8.block.1.1.weight       : 200\n",
      "[2025-07-31 15:26:45,119 INFO 3511189400.py line 61] backbone.8.block.1.1.bias         : 200\n",
      "[2025-07-31 15:26:45,120 INFO 3511189400.py line 61] backbone.8.block.2.0.weight       : 16,000\n",
      "[2025-07-31 15:26:45,121 INFO 3511189400.py line 61] backbone.8.block.2.1.weight       : 80\n",
      "[2025-07-31 15:26:45,122 INFO 3511189400.py line 61] backbone.8.block.2.1.bias         : 80\n",
      "[2025-07-31 15:26:45,123 INFO 3511189400.py line 61] backbone.9.block.0.0.weight       : 14,720\n",
      "[2025-07-31 15:26:45,124 INFO 3511189400.py line 61] backbone.9.block.0.1.weight       : 184\n",
      "[2025-07-31 15:26:45,125 INFO 3511189400.py line 61] backbone.9.block.0.1.bias         : 184\n",
      "[2025-07-31 15:26:45,126 INFO 3511189400.py line 61] backbone.9.block.1.0.weight       : 1,656\n",
      "[2025-07-31 15:26:45,127 INFO 3511189400.py line 61] backbone.9.block.1.1.weight       : 184\n",
      "[2025-07-31 15:26:45,128 INFO 3511189400.py line 61] backbone.9.block.1.1.bias         : 184\n",
      "[2025-07-31 15:26:45,129 INFO 3511189400.py line 61] backbone.9.block.2.0.weight       : 14,720\n",
      "[2025-07-31 15:26:45,130 INFO 3511189400.py line 61] backbone.9.block.2.1.weight       : 80\n",
      "[2025-07-31 15:26:45,131 INFO 3511189400.py line 61] backbone.9.block.2.1.bias         : 80\n",
      "[2025-07-31 15:26:45,131 INFO 3511189400.py line 61] backbone.10.block.0.0.weight      : 14,720\n",
      "[2025-07-31 15:26:45,132 INFO 3511189400.py line 61] backbone.10.block.0.1.weight      : 184\n",
      "[2025-07-31 15:26:45,133 INFO 3511189400.py line 61] backbone.10.block.0.1.bias        : 184\n",
      "[2025-07-31 15:26:45,134 INFO 3511189400.py line 61] backbone.10.block.1.0.weight      : 1,656\n",
      "[2025-07-31 15:26:45,135 INFO 3511189400.py line 61] backbone.10.block.1.1.weight      : 184\n",
      "[2025-07-31 15:26:45,135 INFO 3511189400.py line 61] backbone.10.block.1.1.bias        : 184\n",
      "[2025-07-31 15:26:45,137 INFO 3511189400.py line 61] backbone.10.block.2.0.weight      : 14,720\n",
      "[2025-07-31 15:26:45,140 INFO 3511189400.py line 61] backbone.10.block.2.1.weight      : 80\n",
      "[2025-07-31 15:26:45,143 INFO 3511189400.py line 61] backbone.10.block.2.1.bias        : 80\n",
      "[2025-07-31 15:26:45,145 INFO 3511189400.py line 61] backbone.11.block.0.0.weight      : 38,400\n",
      "[2025-07-31 15:26:45,145 INFO 3511189400.py line 61] backbone.11.block.0.1.weight      : 480\n",
      "[2025-07-31 15:26:45,146 INFO 3511189400.py line 61] backbone.11.block.0.1.bias        : 480\n",
      "[2025-07-31 15:26:45,147 INFO 3511189400.py line 61] backbone.11.block.1.0.weight      : 4,320\n",
      "[2025-07-31 15:26:45,148 INFO 3511189400.py line 61] backbone.11.block.1.1.weight      : 480\n",
      "[2025-07-31 15:26:45,149 INFO 3511189400.py line 61] backbone.11.block.1.1.bias        : 480\n",
      "[2025-07-31 15:26:45,150 INFO 3511189400.py line 61] backbone.11.block.2.fc1.weight    : 57,600\n",
      "[2025-07-31 15:26:45,151 INFO 3511189400.py line 61] backbone.11.block.2.fc1.bias      : 120\n",
      "[2025-07-31 15:26:45,151 INFO 3511189400.py line 61] backbone.11.block.2.fc2.weight    : 57,600\n",
      "[2025-07-31 15:26:45,152 INFO 3511189400.py line 61] backbone.11.block.2.fc2.bias      : 480\n",
      "[2025-07-31 15:26:45,153 INFO 3511189400.py line 61] backbone.11.block.3.0.weight      : 53,760\n",
      "[2025-07-31 15:26:45,154 INFO 3511189400.py line 61] backbone.11.block.3.1.weight      : 112\n",
      "[2025-07-31 15:26:45,155 INFO 3511189400.py line 61] backbone.11.block.3.1.bias        : 112\n",
      "[2025-07-31 15:26:45,161 INFO 3511189400.py line 61] backbone.12.block.0.0.weight      : 75,264\n",
      "[2025-07-31 15:26:45,162 INFO 3511189400.py line 61] backbone.12.block.0.1.weight      : 672\n",
      "[2025-07-31 15:26:45,163 INFO 3511189400.py line 61] backbone.12.block.0.1.bias        : 672\n",
      "[2025-07-31 15:26:45,166 INFO 3511189400.py line 61] backbone.12.block.1.0.weight      : 6,048\n",
      "[2025-07-31 15:26:45,167 INFO 3511189400.py line 61] backbone.12.block.1.1.weight      : 672\n",
      "[2025-07-31 15:26:45,168 INFO 3511189400.py line 61] backbone.12.block.1.1.bias        : 672\n",
      "[2025-07-31 15:26:45,169 INFO 3511189400.py line 61] backbone.12.block.2.fc1.weight    : 112,896\n",
      "[2025-07-31 15:26:45,170 INFO 3511189400.py line 61] backbone.12.block.2.fc1.bias      : 168\n",
      "[2025-07-31 15:26:45,171 INFO 3511189400.py line 61] backbone.12.block.2.fc2.weight    : 112,896\n",
      "[2025-07-31 15:26:45,172 INFO 3511189400.py line 61] backbone.12.block.2.fc2.bias      : 672\n",
      "[2025-07-31 15:26:45,173 INFO 3511189400.py line 61] backbone.12.block.3.0.weight      : 75,264\n",
      "[2025-07-31 15:26:45,174 INFO 3511189400.py line 61] backbone.12.block.3.1.weight      : 112\n",
      "[2025-07-31 15:26:45,175 INFO 3511189400.py line 61] backbone.12.block.3.1.bias        : 112\n",
      "[2025-07-31 15:26:45,176 INFO 3511189400.py line 61] backbone.13.block.0.0.weight      : 75,264\n",
      "[2025-07-31 15:26:45,177 INFO 3511189400.py line 61] backbone.13.block.0.1.weight      : 672\n",
      "[2025-07-31 15:26:45,177 INFO 3511189400.py line 61] backbone.13.block.0.1.bias        : 672\n",
      "[2025-07-31 15:26:45,178 INFO 3511189400.py line 61] backbone.13.block.1.0.weight      : 16,800\n",
      "[2025-07-31 15:26:45,179 INFO 3511189400.py line 61] backbone.13.block.1.1.weight      : 672\n",
      "[2025-07-31 15:26:45,180 INFO 3511189400.py line 61] backbone.13.block.1.1.bias        : 672\n",
      "[2025-07-31 15:26:45,181 INFO 3511189400.py line 61] backbone.13.block.2.fc1.weight    : 112,896\n",
      "[2025-07-31 15:26:45,182 INFO 3511189400.py line 61] backbone.13.block.2.fc1.bias      : 168\n",
      "[2025-07-31 15:26:45,183 INFO 3511189400.py line 61] backbone.13.block.2.fc2.weight    : 112,896\n",
      "[2025-07-31 15:26:45,184 INFO 3511189400.py line 61] backbone.13.block.2.fc2.bias      : 672\n",
      "[2025-07-31 15:26:45,184 INFO 3511189400.py line 61] backbone.13.block.3.0.weight      : 107,520\n",
      "[2025-07-31 15:26:45,186 INFO 3511189400.py line 61] backbone.13.block.3.1.weight      : 160\n",
      "[2025-07-31 15:26:45,187 INFO 3511189400.py line 61] backbone.13.block.3.1.bias        : 160\n",
      "[2025-07-31 15:26:45,188 INFO 3511189400.py line 61] backbone.14.block.0.0.weight      : 153,600\n",
      "[2025-07-31 15:26:45,188 INFO 3511189400.py line 61] backbone.14.block.0.1.weight      : 960\n",
      "[2025-07-31 15:26:45,189 INFO 3511189400.py line 61] backbone.14.block.0.1.bias        : 960\n",
      "[2025-07-31 15:26:45,189 INFO 3511189400.py line 61] backbone.14.block.1.0.weight      : 24,000\n",
      "[2025-07-31 15:26:45,190 INFO 3511189400.py line 61] backbone.14.block.1.1.weight      : 960\n",
      "[2025-07-31 15:26:45,191 INFO 3511189400.py line 61] backbone.14.block.1.1.bias        : 960\n",
      "[2025-07-31 15:26:45,193 INFO 3511189400.py line 61] backbone.14.block.2.fc1.weight    : 230,400\n",
      "[2025-07-31 15:26:45,194 INFO 3511189400.py line 61] backbone.14.block.2.fc1.bias      : 240\n",
      "[2025-07-31 15:26:45,194 INFO 3511189400.py line 61] backbone.14.block.2.fc2.weight    : 230,400\n",
      "[2025-07-31 15:26:45,195 INFO 3511189400.py line 61] backbone.14.block.2.fc2.bias      : 960\n",
      "[2025-07-31 15:26:45,196 INFO 3511189400.py line 61] backbone.14.block.3.0.weight      : 153,600\n",
      "[2025-07-31 15:26:45,197 INFO 3511189400.py line 61] backbone.14.block.3.1.weight      : 160\n",
      "[2025-07-31 15:26:45,198 INFO 3511189400.py line 61] backbone.14.block.3.1.bias        : 160\n",
      "[2025-07-31 15:26:45,199 INFO 3511189400.py line 61] backbone.15.block.0.0.weight      : 153,600\n",
      "[2025-07-31 15:26:45,199 INFO 3511189400.py line 61] backbone.15.block.0.1.weight      : 960\n",
      "[2025-07-31 15:26:45,200 INFO 3511189400.py line 61] backbone.15.block.0.1.bias        : 960\n",
      "[2025-07-31 15:26:45,201 INFO 3511189400.py line 61] backbone.15.block.1.0.weight      : 24,000\n",
      "[2025-07-31 15:26:45,202 INFO 3511189400.py line 61] backbone.15.block.1.1.weight      : 960\n",
      "[2025-07-31 15:26:45,203 INFO 3511189400.py line 61] backbone.15.block.1.1.bias        : 960\n",
      "[2025-07-31 15:26:45,204 INFO 3511189400.py line 61] backbone.15.block.2.fc1.weight    : 230,400\n",
      "[2025-07-31 15:26:45,205 INFO 3511189400.py line 61] backbone.15.block.2.fc1.bias      : 240\n",
      "[2025-07-31 15:26:45,208 INFO 3511189400.py line 61] backbone.15.block.2.fc2.weight    : 230,400\n",
      "[2025-07-31 15:26:45,209 INFO 3511189400.py line 61] backbone.15.block.2.fc2.bias      : 960\n",
      "[2025-07-31 15:26:45,210 INFO 3511189400.py line 61] backbone.15.block.3.0.weight      : 153,600\n",
      "[2025-07-31 15:26:45,211 INFO 3511189400.py line 61] backbone.15.block.3.1.weight      : 160\n",
      "[2025-07-31 15:26:45,212 INFO 3511189400.py line 61] backbone.15.block.3.1.bias        : 160\n",
      "[2025-07-31 15:26:45,213 INFO 3511189400.py line 61] backbone.16.0.weight              : 153,600\n",
      "[2025-07-31 15:26:45,214 INFO 3511189400.py line 61] backbone.16.1.weight              : 960\n",
      "[2025-07-31 15:26:45,215 INFO 3511189400.py line 61] backbone.16.1.bias                : 960\n",
      "[2025-07-31 15:26:45,216 INFO 3511189400.py line 61] classifier.cbr.0.weight           : 122,880\n",
      "[2025-07-31 15:26:45,217 INFO 3511189400.py line 61] classifier.cbr.1.weight           : 128\n",
      "[2025-07-31 15:26:45,218 INFO 3511189400.py line 61] classifier.cbr.1.bias             : 128\n",
      "[2025-07-31 15:26:45,219 INFO 3511189400.py line 61] classifier.scale.1.weight         : 122,880\n",
      "[2025-07-31 15:26:45,220 INFO 3511189400.py line 61] classifier.low_classifier.weight  : 840\n",
      "[2025-07-31 15:26:45,221 INFO 3511189400.py line 61] classifier.low_classifier.bias    : 21\n",
      "[2025-07-31 15:26:45,222 INFO 3511189400.py line 61] classifier.high_classifier.weight : 2,688\n",
      "[2025-07-31 15:26:45,223 INFO 3511189400.py line 61] classifier.high_classifier.bias   : 21\n",
      "[2025-07-31 15:26:45,224 INFO 3511189400.py line 61] Total: 3,221,538\n",
      "[2025-07-31 15:26:45,226 INFO 1299961493.py line 52] ---------------------------------------[ Initial Validation ]---------------------------------------\n",
      "[2025-07-31 15:26:54,514 INFO 1299961493.py line 54] [Before any weight update, VALIDATION] val_loss: 0.1865, val_acc: 0.9400, val_mIoU: 0.5660\n",
      "[2025-07-31 15:26:54,516 INFO 1299961493.py line 57] -----------------------------------------[ Training Start ]-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, batch_loss=tensor(5.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "step=1, batch_loss=tensor(5.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "step=2, batch_loss=tensor(5.9506, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     61\u001b[39m [log_manager.log_line(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m get_layer_numel_str(segnet, print_only_total=\u001b[38;5;28;01mFalse\u001b[39;00m, only_trainable=\u001b[38;5;28;01mTrue\u001b[39;00m).split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)]\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m train_loop(\n\u001b[32m     65\u001b[39m     segnet,\n\u001b[32m     66\u001b[39m     vlm,\n\u001b[32m     67\u001b[39m     vle,\n\u001b[32m     68\u001b[39m     train_dl,\n\u001b[32m     69\u001b[39m     val_dl,\n\u001b[32m     70\u001b[39m     fast_prompt_builder,\n\u001b[32m     71\u001b[39m     seg_preprocess_fn,\n\u001b[32m     72\u001b[39m     gen_params,\n\u001b[32m     73\u001b[39m     criterion,\n\u001b[32m     74\u001b[39m     contr_criterion,\n\u001b[32m     75\u001b[39m     metrics_dict,\n\u001b[32m     76\u001b[39m     checkpoint_dict\n\u001b[32m     77\u001b[39m )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m     79\u001b[39m     log_manager.log_title(\u001b[33m\"\u001b[39m\u001b[33mTraining Interrupted\u001b[39m\u001b[33m\"\u001b[39m, pad_symbol=\u001b[33m'\u001b[39m\u001b[33m~\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(segnet, vlm, vle, train_dl, val_dl, fast_prompt_builder, seg_preprocess_fn, gen_params, criterion, contr_criterion, metrics_dict, checkpoint_dict)\u001b[39m\n\u001b[32m     94\u001b[39m cs_prompts = fast_prompt_builder.build_cs_inference_prompts(gts_down, prs_down, scs_down)\n\u001b[32m     96\u001b[39m batch_idxs = [train_dl.batch_size*step + i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scs_down))]\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m cs_answer_list = \u001b[38;5;28;01mawait\u001b[39;00m vlm.predict_many_class_splitted(\n\u001b[32m     99\u001b[39m     cs_prompts,\n\u001b[32m    100\u001b[39m     batch_idxs,\n\u001b[32m    101\u001b[39m     gen_params=gen_params,\n\u001b[32m    102\u001b[39m     jsonl_save_path=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    103\u001b[39m     only_text=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    104\u001b[39m     splits_in_parallel=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    105\u001b[39m     batch_size=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    106\u001b[39m     use_tqdm=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    107\u001b[39m )\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# --- VLE --- #\u001b[39;00m\n\u001b[32m    111\u001b[39m global_text_tokens = \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/exp/src/models/vl_models.py:485\u001b[39m, in \u001b[36mMLLM.predict_many_class_splitted\u001b[39m\u001b[34m(self, class_splitted_query_prompts, query_idxs, gen_params, jsonl_save_path, system_prompt, only_text, parse_to_dict, splits_in_parallel, batch_size, cooldown_period, use_tqdm)\u001b[39m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, (img_idx, q_p_class_splitted) \u001b[38;5;129;01min\u001b[39;00m my_tqdm_(\u001b[38;5;28mzip\u001b[39m(query_idxs, class_splitted_query_prompts)):  \n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m         answer_pr = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict_one_class_splitted(\n\u001b[32m    486\u001b[39m             q_p_class_splitted,\n\u001b[32m    487\u001b[39m             img_idx,\n\u001b[32m    488\u001b[39m             gen_params=gen_params,\n\u001b[32m    489\u001b[39m             system_prompt=system_prompt,\n\u001b[32m    490\u001b[39m             only_text=only_text,\n\u001b[32m    491\u001b[39m             parse_to_dict=parse_to_dict,\n\u001b[32m    492\u001b[39m             splits_in_parallel=splits_in_parallel\n\u001b[32m    493\u001b[39m         )\n\u001b[32m    495\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m jsonl_save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    496\u001b[39m             append_many_to_jsonl(jsonl_save_path, [answer_pr])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/exp/src/models/vl_models.py:369\u001b[39m, in \u001b[36mMLLM.predict_one_class_splitted\u001b[39m\u001b[34m(self, class_splitted_query_prompt, query_idx, gen_params, system_prompt, only_text, parse_to_dict, splits_in_parallel)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c, q_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(significant_classes, query_prompts):\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m         class_splitted_answer_pr = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict_one(\n\u001b[32m    370\u001b[39m             q_p,\n\u001b[32m    371\u001b[39m             query_idx=query_idx,\n\u001b[32m    372\u001b[39m             gen_params=gen_params,\n\u001b[32m    373\u001b[39m             system_prompt=system_prompt,\n\u001b[32m    374\u001b[39m             only_text=only_text,\n\u001b[32m    375\u001b[39m             parse_to_dict=parse_to_dict\n\u001b[32m    376\u001b[39m         )\n\u001b[32m    378\u001b[39m         outs[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m].update({c: class_splitted_answer_pr[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]})\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/exp/src/models/vl_models.py:204\u001b[39m, in \u001b[36mMLLM.predict_one\u001b[39m\u001b[34m(self, query_prompt, query_idx, gen_params, system_prompt, only_text, parse_to_dict)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03mPredicts a response for a single prompt.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    199\u001b[39m \u001b[33;03m    Dictionary with image index and content.\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    202\u001b[39m conv = \u001b[38;5;28mself\u001b[39m.convert_prompt_to_conv(query_prompt, system_prompt)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m answer_response: Response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_response(\n\u001b[32m    205\u001b[39m     conv,\n\u001b[32m    206\u001b[39m     gen_params=gen_params,\n\u001b[32m    207\u001b[39m     stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    208\u001b[39m )\n\u001b[32m    210\u001b[39m out: Response = \u001b[38;5;28mself\u001b[39m.adapt_response(answer_response)\n\u001b[32m    211\u001b[39m out = \u001b[38;5;28mself\u001b[39m.process_response(out, only_text=only_text, parse_to_dict=parse_to_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/exp/src/models/vl_models.py:728\u001b[39m, in \u001b[36mOllamaMLLM.generate_response\u001b[39m\u001b[34m(self, conversation, gen_params, stream)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_response\u001b[39m(\n\u001b[32m    711\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    712\u001b[39m         conversation: Conversation,\n\u001b[32m    713\u001b[39m         gen_params: GenParams,\n\u001b[32m    714\u001b[39m         stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    715\u001b[39m ) -> ollama.ChatResponse | Generator[ollama.ChatResponse, \u001b[38;5;28;01mNone\u001b[39;00m, ollama.ChatResponse] | AsyncGenerator[ollama.ChatResponse, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    716\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m    Generates a response using Ollama.\u001b[39;00m\n\u001b[32m    718\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    725\u001b[39m \u001b[33;03m        Ollama ChatResponse or generator/async generator of responses.\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m     response_or_generator: ollama.ChatResponse = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat(\n\u001b[32m    729\u001b[39m         model=\u001b[38;5;28mself\u001b[39m.model, \n\u001b[32m    730\u001b[39m         messages=conversation,\n\u001b[32m    731\u001b[39m         options={\n\u001b[32m    732\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnum_ctx\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mctx_size\u001b[39m\u001b[33m\"\u001b[39m] ,\n\u001b[32m    733\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrepeat_last_n\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mlast_n_not_to_repeat\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    734\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrepeat_penalty\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mrepeat_penalty\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    735\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    736\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    737\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    738\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnum_predict\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    739\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    740\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    741\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmin_p\u001b[39m\u001b[33m\"\u001b[39m: gen_params[\u001b[33m\"\u001b[39m\u001b[33mmin_p\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    742\u001b[39m         },\n\u001b[32m    743\u001b[39m         \u001b[38;5;28mformat\u001b[39m=gen_params[\u001b[33m\"\u001b[39m\u001b[33manswer_format\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    744\u001b[39m         stream=stream\n\u001b[32m    745\u001b[39m     ) \u001b[38;5;66;03m# generate response or generator of responses\u001b[39;00m\n\u001b[32m    747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_or_generator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/ollama/_client.py:854\u001b[39m, in \u001b[36mAsyncClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    809\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    810\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    818\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    819\u001b[39m ) -> Union[ChatResponse, AsyncIterator[ChatResponse]]:\n\u001b[32m    820\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    822\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    851\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns an asynchronous `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    852\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m    855\u001b[39m     ChatResponse,\n\u001b[32m    856\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    857\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m/api/chat\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    858\u001b[39m     json=ChatRequest(\n\u001b[32m    859\u001b[39m       model=model,\n\u001b[32m    860\u001b[39m       messages=\u001b[38;5;28mlist\u001b[39m(_copy_messages(messages)),\n\u001b[32m    861\u001b[39m       tools=\u001b[38;5;28mlist\u001b[39m(_copy_tools(tools)),\n\u001b[32m    862\u001b[39m       stream=stream,\n\u001b[32m    863\u001b[39m       think=think,\n\u001b[32m    864\u001b[39m       \u001b[38;5;28mformat\u001b[39m=\u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    865\u001b[39m       options=options,\n\u001b[32m    866\u001b[39m       keep_alive=keep_alive,\n\u001b[32m    867\u001b[39m     ).model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    868\u001b[39m     stream=stream,\n\u001b[32m    869\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/ollama/_client.py:692\u001b[39m, in \u001b[36mAsyncClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    690\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_raw(*args, **kwargs)).json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/ollama/_client.py:632\u001b[39m, in \u001b[36mAsyncClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    631\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     r = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.request(*args, **kwargs)\n\u001b[32m    633\u001b[39m     r.raise_for_status()\n\u001b[32m    634\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.11/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "seg_preprocess_fn = partial(SemanticSegmentation, resize_size=SEG_CONFIG['image_size'])() #Â same as original one, but with custom resizing\n",
    "\n",
    "# training cropping functions\n",
    "center_crop_fn = T.CenterCrop(SEG_CONFIG['image_size'])\n",
    "random_crop_fn = T.RandomCrop(SEG_CONFIG['image_size'])\n",
    "\n",
    "# augmentations\n",
    "augment_fn = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    # T.RandomAffine(degrees=0, scale=(0.5, 2)), # Zooms in and out of the image.\n",
    "    # T.RandomAffine(degrees=[-30, 30], translate=[0.2, 0.2], scale=(0.5, 2), shear=15), # Full affine transform.\n",
    "    #Â T.RandomPerspective(p=0.5, distortion_scale=0.2) #Â Shears the image\n",
    "])\n",
    "\n",
    "train_collate_fn = partial(\n",
    "    crop_augment_preprocess_batch,\n",
    "    crop_fn=random_crop_fn,\n",
    "    augment_fn=augment_fn,\n",
    "    preprocess_fn=None\n",
    ")\n",
    "\n",
    "val_collate_fn = partial(\n",
    "    crop_augment_preprocess_batch,\n",
    "    crop_fn=T.CenterCrop(SEG_CONFIG['image_size']),\n",
    "    augment_fn=None,\n",
    "    preprocess_fn=seg_preprocess_fn\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=21)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=SEG_TRAIN_CONFIG[\"batch_size\"],\n",
    "    shuffle=False, # TODO SET TO TRUE\n",
    "    generator=get_torch_gen(),\n",
    "    collate_fn=train_collate_fn,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=SEG_TRAIN_CONFIG[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    generator=get_torch_gen(),\n",
    "    collate_fn=val_collate_fn,\n",
    ")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"acc\": MulticlassAccuracy(num_classes=train_ds.get_num_classes(with_unlabelled=True), top_k=1, average=\"micro\", multidim_average=\"global\", ignore_index=21).to(CONFIG[\"device\"]),\n",
    "    \"mIoU\": MulticlassJaccardIndex(num_classes=train_ds.get_num_classes(with_unlabelled=True), average=\"macro\", ignore_index=21).to(CONFIG[\"device\"]),\n",
    "}\n",
    "\n",
    "log_manager.log_intro(\n",
    "    config=CONFIG,\n",
    "    train_ds=train_ds,\n",
    "    val_ds=val_ds,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl\n",
    ")\n",
    "\n",
    "# Log trainable parameters\n",
    "log_manager.log_title(\"Trainable Params\")\n",
    "[log_manager.log_line(t) for t in get_layer_numel_str(segnet, print_only_total=False, only_trainable=True).split('\\n')]\n",
    "\n",
    "try:\n",
    "    await train_loop(\n",
    "    segnet,\n",
    "    vlm,\n",
    "    vle,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    fast_prompt_builder,\n",
    "    seg_preprocess_fn,\n",
    "    gen_params,\n",
    "    criterion,\n",
    "    contr_criterion,\n",
    "    metrics_dict,\n",
    "    checkpoint_dict\n",
    ")\n",
    "except KeyboardInterrupt:\n",
    "    log_manager.log_title(\"Training Interrupted\", pad_symbol='~')\n",
    "\n",
    "handle.remove()\n",
    "\n",
    "log_manager.close_loggers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
