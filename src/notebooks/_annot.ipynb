{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9268472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "root_path = Path(\"/home/olivieri/exp\").resolve()\n",
    "src_path = root_path / \"src\"\n",
    "sys.path.append(f\"{str(src_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70b571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "from annot import *\n",
    "from prompter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8cd9b8",
   "metadata": {},
   "source": [
    "# Annotation Doc Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18579200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "BY_MODEL = \"LRASPP_MobileNet_V3\"\n",
    "SPLIT_BY = \"non-splitted\"\n",
    "\n",
    "promptBuilder = PromptBuilder(\n",
    "    by_model            = BY_MODEL,\n",
    "    alpha               = 0.4,\n",
    "    image_size          = 520,\n",
    "    array_size          = (32, 32),\n",
    "    class_map           = CLASS_MAP, # imported from 'class_map.py'\n",
    "    color_map           = COLOR_MAP_DICT,\n",
    "    split_by            = SPLIT_BY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8e7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptBuilder.load_modules(\n",
    "    context_module          = ContextModule(variation=\"default\"),\n",
    "    color_map_module        = Image_ColorMapModule(variation=\"default\"),\n",
    "    input_format_module     = ConcatMasks_Ovr_Hz_InputFormatModule(\"original\"),\n",
    "    task_module             = TaskModule(variation=\"default\"),\n",
    "    output_format_module    = OutputFormatModule(variation=\"default\"),\n",
    "    support_set_module      = SupportSetModule(variation=\"default\", sup_set_idxs=(16,2,18)),\n",
    "    query_module            = QueryModule(variation=\"default\"),\n",
    "    eval_module             = EvalModule(variation=\"7_incomplet+strict+precision+error_types+spatial_locs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2daee",
   "metadata": {},
   "source": [
    "Build and upload the formatted images to a local folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1eb143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_formatted_images(promptBuilder, tuple(range(0, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = upload_local_images_to_gdrive(tuple(range(0, 100)), \"1EEEFXxdG8asPQf58hoevIscpvbhyfvt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666a7f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_objects = list_file_ids_in_folder(GDRIVE_ANNOT_IMGS_PATH)\n",
    "cmap_object, img_objects = file_objects[0], file_objects[1:] # the first image in the dir should be the color map\n",
    "_, cmap_id, _ = cmap_object\n",
    "_, img_ids, _ = zip(*img_objects)\n",
    "len(file_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_UIDs[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78abd637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('annot_image_2007_000175',\n",
       " '1d9jvUdQGzNDsQZzMryc_nRvUp8v3wvZR',\n",
       " {'width': 1130, 'height': 600, 'rotation': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_objects[14-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab6455",
   "metadata": {},
   "source": [
    "Write the **whole** annotation document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff24c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('annot_image_2007_000032',\n",
       " 'annot_image_2007_000033',\n",
       " 'annot_image_2007_000039',\n",
       " 'annot_image_2007_000042',\n",
       " 'annot_image_2007_000061',\n",
       " 'annot_image_2007_000063',\n",
       " 'annot_image_2007_000068',\n",
       " 'annot_image_2008_000073',\n",
       " 'annot_image_2007_000121',\n",
       " 'annot_image_2007_000123',\n",
       " 'annot_image_2007_000129',\n",
       " 'annot_image_2007_000170',\n",
       " 'annot_image_2007_000175',\n",
       " 'annot_image_2009_000177',\n",
       " 'annot_image_2007_000187',\n",
       " 'annot_image_2007_000241',\n",
       " 'annot_image_2007_000243',\n",
       " 'annot_image_2007_000250',\n",
       " 'annot_image_2007_000256',\n",
       " 'annot_image_2007_000323',\n",
       " 'annot_image_2007_000332',\n",
       " 'annot_image_2007_000333',\n",
       " 'annot_image_2007_000346',\n",
       " 'annot_image_2007_000363',\n",
       " 'annot_image_2007_000364',\n",
       " 'annot_image_2008_000464',\n",
       " 'annot_image_2009_000487',\n",
       " 'annot_image_2009_000553',\n",
       " 'annot_image_2008_000630',\n",
       " 'annot_image_2011_000658',\n",
       " 'annot_image_2010_000679',\n",
       " 'annot_image_2009_000684',\n",
       " 'annot_image_2011_000780',\n",
       " 'annot_image_2011_000920',\n",
       " 'annot_image_2011_000973',\n",
       " 'annot_image_2010_001070',\n",
       " 'annot_image_2009_001082',\n",
       " 'annot_image_2010_001246',\n",
       " 'annot_image_2007_001458',\n",
       " 'annot_image_2008_001498',\n",
       " 'annot_image_2011_001589',\n",
       " 'annot_image_2007_001594',\n",
       " 'annot_image_2009_001684',\n",
       " 'annot_image_2010_001692',\n",
       " 'annot_image_2008_001719',\n",
       " 'annot_image_2008_001829',\n",
       " 'annot_image_2007_001857',\n",
       " 'annot_image_2011_001895',\n",
       " 'annot_image_2010_001922',\n",
       " 'annot_image_2011_002124',\n",
       " 'annot_image_2011_002156',\n",
       " 'annot_image_2008_002175',\n",
       " 'annot_image_2011_002223',\n",
       " 'annot_image_2008_002241',\n",
       " 'annot_image_2010_002271',\n",
       " 'annot_image_2011_002308',\n",
       " 'annot_image_2010_002418',\n",
       " 'annot_image_2009_002487',\n",
       " 'annot_image_2011_002561',\n",
       " 'annot_image_2007_002669',\n",
       " 'annot_image_2011_002685',\n",
       " 'annot_image_2011_002713',\n",
       " 'annot_image_2009_002727',\n",
       " 'annot_image_2009_002885',\n",
       " 'annot_image_2008_002885',\n",
       " 'annot_image_2008_002900',\n",
       " 'annot_image_2007_002903',\n",
       " 'annot_image_2009_002932',\n",
       " 'annot_image_2011_003151',\n",
       " 'annot_image_2008_003373',\n",
       " 'annot_image_2010_003383',\n",
       " 'annot_image_2010_003468',\n",
       " 'annot_image_2010_003531',\n",
       " 'annot_image_2008_003703',\n",
       " 'annot_image_2009_003711',\n",
       " 'annot_image_2007_003714',\n",
       " 'annot_image_2010_003772',\n",
       " 'annot_image_2007_003841',\n",
       " 'annot_image_2009_003991',\n",
       " 'annot_image_2010_004074',\n",
       " 'annot_image_2007_004291',\n",
       " 'annot_image_2007_004538',\n",
       " 'annot_image_2010_004560',\n",
       " 'annot_image_2010_004772',\n",
       " 'annot_image_2010_004815',\n",
       " 'annot_image_2009_005000',\n",
       " 'annot_image_2009_005190',\n",
       " 'annot_image_2009_005287',\n",
       " 'annot_image_2008_005338',\n",
       " 'annot_image_2010_005496',\n",
       " 'annot_image_2007_006232',\n",
       " 'annot_image_2007_006254',\n",
       " 'annot_image_2007_006641',\n",
       " 'annot_image_2008_006784',\n",
       " 'annot_image_2007_007203',\n",
       " 'annot_image_2007_007230',\n",
       " 'annot_image_2007_007355',\n",
       " 'annot_image_2008_008252',\n",
       " 'annot_image_2007_009139',\n",
       " 'annot_image_2007_009947')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, _, _ = zip(*img_objects)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19762f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_annot_doc(os.getenv(\"CHIARA_GDOC_ID\"), \"Chiara\", range(20, 30), promptBuilder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac7f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The part of the CAT on the top left part of the image is not well segmented, indeed some part of the BACKGROUND has been misclassified as CAT. Furthermore on the right part there is a little bit of noise in the segmentation of the CAT.',\n",
       " 'The COW is almost completely misclassified. Indeed there are only the ears and some little parts that are segmented correctly. The prediction shows colors for other things, such as HORSE.',\n",
       " 'The segmentation is done pretty well a part from the boundaries. Because of this  some details of the BUS are missing.',\n",
       " 'The BOAT is quite well classified, a part from the borders. The PERSON is not classified at all.',\n",
       " '',\n",
       " 'Both the ground truth and the prediction are not segmented 100% correctly. The bottom part of both segmentation does not have defined boundaries. The top part of the prediction is not classified as BOTTLE:',\n",
       " 'The PLANE is quite well segmented.  There are some boundaries that are not well defined in both ground truth and prediction.',\n",
       " 'The two people are predicted not very well. The boundaries are completely misclassified,',\n",
       " 'The PEOPLE are classified as SOFA  and the borders of the SOFA are not well defined.',\n",
       " 'The BOTTLE is not well classified. There are parts of the table classified as BOTTLE. The CAT’s boundaries are not well defined.',\n",
       " 'The CAR is not segmented well in both the ground truth and prediction. THe background is also misclassified as CAR. The boundaries are completely wrong in the prediction and they are not well delineated in the ground truth.',\n",
       " 'The COW’s borders are not precise in the ground truth. In the prediction instead, there are some parts of the background that are misclassified as COW. The right part of the COW in the prediction is not well defined either.',\n",
       " 'The DININGTABLE and the CHAIRs are completely misclassified in the prediction. The POTTEDPLANT is completely wrongly segmented in the groundtruth and there is one region segmented in the prediction, even if the boundaries are wrong.',\n",
       " 'The ground truth DOG is well segmented (without considering the boundaries). The prediction misclassified a lot of parts of the DOG, considering also the BACKGROUND and other different elements (such as it classifies a region as AIRPLANE that is completely wrong).',\n",
       " 'The SHEEP are misclassified mostly as BACKGROUND in the prediction. Also the DOG is not classified as DOG in the prediction but as BYCICLE. The PERSON is classified but the borders are segmented badly and they are not well defined.',\n",
       " 'The BOTTLE in the ground truth is segmented really bad in the prediction. The borders are coarse and basically there are almost no boundaries. Also some parts of the BACKGROUND are considered as BOTTLE.',\n",
       " 'The prediction borders of the PERSON are not defined. The AEROPLANE is classified correctly but the boundaries are badly segmented.',\n",
       " 'The SOFA is almost all misclassified as BACKGROUND. There are only some little parts segmented and predicted as SOFA.',\n",
       " 'The PERSON are segmented quite well but they do not have boundaries anymore and they are merged in one single region. The DININGTABLE has been well segmented, a part from the boundaries.',\n",
       " 'The CAR is not segmented almost at all. The boundaries of the PERSON are poorly segmented.',\n",
       " 'The DOG is well classified a part from one part on the head that is misclassified as DININGTABLE.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots = extract_table_content_from_gdoc(os.getenv(\"SARA_GDOC_ID\"))\n",
    "annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e18253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append_many_to_jsonl(\"/home/olivieri/exp/data/VOCdevkit/VOC2012/MyAnnotations/by_model/LRASPP_MobileNet_V3/answer_gts.jsonl\", [{\"img_idx\": i, \"content\": annot} for (i, annot) in zip(range(40, 60), annots)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
